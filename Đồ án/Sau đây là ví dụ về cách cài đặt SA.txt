Sau đây là ví dụ về cách cài đặt SARSA và DQN sử dụng Keras-RL. Đầu tiên, bạn cần cài đặt các thư viện cần thiết bằng cách chạy:

```sh
pip install keras-rl2
pip install tensorflow==2.3.0
pip install gym
```

1. Cài đặt SARSA:

```python
import numpy as np
import gym

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.optimizers import Adam

from rl.agents import SarsaAgent
from rl.policy import BoltzmannQPolicy
from rl.memory import SequentialMemory

def build_model(states, actions):
    model = Sequential()
    model.add(Flatten(input_shape=(1,) + states))
    model.add(Dense(24, activation='relu'))
    model.add(Dense(24, activation='relu'))
    model.add(Dense(actions, activation='linear'))
    return model

def test_sarsa(ENV_NAME):
    # Get the environment and extract information about it.
    env = gym.make(ENV_NAME)
    np.random.seed(123)
    env.seed(123)
    nb_actions = env.action_space.n
    states = env.observation_space.shape

    model = build_model(states, nb_actions)
    
    # SARSA agent
    memory = SequentialMemory(limit=50000, window_length=1)
    policy = BoltzmannQPolicy()
    sarsa = SarsaAgent(model=model, nb_actions=nb_actions, nb_steps_warmup=10, policy=policy, memory=memory)
    sarsa.compile(Adam(lr=1e-3), metrics=['mae'])
    sarsa.fit(env, nb_steps=50000, visualize=False, verbose=1)
    sarsa.test(env, nb_episodes=5, visualize=True)  # Set visualize to True to see the agent in action

if __name__ == "__main__":
    ENV_NAME = 'CartPole-v1'
    test_sarsa(ENV_NAME)
```

2. Cài đặt DQN:

```python
import numpy as np
import gym

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.optimizers import Adam

from rl.agents import DQNAgent
from rl.policy import EpsGreedyQPolicy
from rl.memory import SequentialMemory

def build_model(states, actions):
    model = Sequential()
    model.add(Flatten(input_shape=(1,) + states))
    model.add(Dense(24, activation='relu'))
    model.add(Dense(24, activation='relu'))
    model.add(Dense(actions, activation='linear'))
    return model

def test_dqn(ENV_NAME):
    # Get the environment and extract information about it.
    env = gym.make(ENV_NAME)
    np.random.seed(123)
    env.seed(123)
    nb_actions = env.action_space.n
    states = env.observation_space.shape

    model = build_model(states, nb_actions)
    
    # DQN agent
    memory = SequentialMemory(limit=50000, window_length=1)
    policy = EpsGreedyQPolicy()
    dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=10, target_model_update=1e-2, policy=policy)
    dqn.compile(Adam(lr=1e-3), metrics=['mae'])
    dqn.fit(env, nb_steps=50000, visualize=False, verbose=1)
    dqn.test(env, nb_episodes=5, visualize=True)  # Set visualize to True to see the agent in action

if __name__ == "__main__":
    ENV_NAME = 'CartPole-v1'
    test_dqn(ENV_NAME)
```

Để chạy các tập lệnh trên, bạn có thể lưu chúng dưới dạng tệp Python và chạy `python sarsa.py` hoặc `python dqn.py` tùy thuộc vào thuật toán bạn muốn kiểm tra. Đảm bảo rằng bạn đã cài đặt các gói cần thiết (keras-rl2, tensorflow, gym) trước khi chạy các tập lệnh.